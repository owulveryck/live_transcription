<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Live Audio Transcription</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            padding: 20px;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 30px;
        }

        .control-panel {
            display: flex;
            flex-wrap: wrap;
            gap: 20px;
            margin-bottom: 30px;
            padding: 20px;
            background: #f8f9fa;
            border-radius: 8px;
            align-items: end;
        }

        .form-group {
            display: flex;
            flex-direction: column;
            min-width: 200px;
        }

        .form-label {
            font-weight: 500;
            margin-bottom: 5px;
            color: #555;
        }

        .form-control {
            padding: 8px 12px;
            border: 1px solid #ddd;
            border-radius: 4px;
            font-size: 14px;
        }

        .recording-mode-options {
            display: flex;
            gap: 15px;
        }

        .mode-option {
            display: flex;
            align-items: center;
            gap: 5px;
        }

        .mode-option input[type="radio"] {
            margin: 0;
        }

        .btn {
            padding: 10px 20px;
            border: none;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            display: flex;
            align-items: center;
            gap: 8px;
            transition: background-color 0.2s;
        }

        .btn-primary {
            background-color: #007bff;
            color: white;
        }

        .btn-primary:hover {
            background-color: #0056b3;
        }

        .btn-danger {
            background-color: #dc3545;
            color: white;
        }

        .btn-danger:hover {
            background-color: #c82333;
        }

        .btn-outline {
            background-color: transparent;
            color: #6c757d;
            border: 1px solid #6c757d;
        }

        .btn-outline:hover {
            background-color: #6c757d;
            color: white;
        }

        .btn:disabled {
            opacity: 0.6;
            cursor: not-allowed;
        }

        .recording-status {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 10px;
            padding: 15px;
            background: #d4edda;
            border: 1px solid #c3e6cb;
            border-radius: 4px;
            margin-bottom: 20px;
            color: #155724;
        }

        .recording-status.hidden {
            display: none;
        }

        .recording-dot {
            width: 12px;
            height: 12px;
            background-color: #dc3545;
            border-radius: 50%;
            animation: pulse 2s infinite;
        }

        .recording-time {
            font-weight: bold;
            margin-left: 10px;
        }

        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }

        .audio-visualizer {
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100px;
            background: #f8f9fa;
            border-radius: 8px;
            margin-bottom: 20px;
            padding: 10px;
        }

        .audio-visualizer.hidden {
            display: none;
        }

        .audio-visualizer-bars {
            display: flex;
            align-items: end;
            gap: 2px;
            height: 80px;
        }

        .visualizer-bar {
            width: 4px;
            background: linear-gradient(to top, #007bff, #00d4ff);
            border-radius: 2px;
            min-height: 5%;
            transition: height 0.1s ease;
        }

        .transcription-container {
            flex: 1;
            margin-right: 20px; /* Space between transcription and summary */
        }

        .summary-container {
            flex: 1;
        }

        .summary-output {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
        }

        .summary-output.empty {
            color: #6c757d;
            font-style: italic;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        /* Flexbox for main content area */
        .main-content-area {
            display: flex;
            justify-content: space-between;
            margin-top: 30px;
        }

        @media (max-width: 992px) {
            .main-content-area {
                flex-direction: column;
            }

            .transcription-container {
                margin-right: 0;
                margin-bottom: 20px;
            }
        }

        .transcription-output {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 20px;
            min-height: 200px;
            max-height: 400px;
            overflow-y: auto;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
        }

        .transcription-output.empty {
            color: #6c757d;
            font-style: italic;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .transcript-entry {
            margin-bottom: 15px;
            padding: 10px;
            border-radius: 6px;
            border-left: 4px solid #007bff;
            background: white;
        }

        .transcript-entry.final {
            border-left-color: #28a745;
            background: #f8fff9;
        }

        .transcript-entry.response {
            border-left-color: #ffc107;
            background: #fffef8;
        }

        .transcript-meta {
            font-size: 0.85em;
            color: #6c757d;
            margin-bottom: 5px;
        }

        .transcript-text {
            color: #333;
            font-size: 1em;
        }

        .transcript-entry.interim .transcript-text {
            color: #666;
            font-style: italic;
        }

        .clear-transcripts {
            margin-bottom: 15px;
        }

        .stats-container {
            display: flex;
            justify-content: space-between;
            margin-bottom: 15px;
            padding: 10px;
            background: #e9ecef;
            border-radius: 6px;
            font-size: 0.9em;
        }

        .stat-item {
            text-align: center;
        }

        .stat-value {
            font-weight: bold;
            color: #007bff;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 10px;
            border-radius: 4px;
            margin-bottom: 20px;
        }

        .status-indicator.connected {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }

        .status-indicator.disconnected {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }

        .status-indicator.connecting {
            background: #fff3cd;
            color: #856404;
            border: 1px solid #ffeaa7;
        }

        .form-hint {
            font-size: 12px;
            color: #6c757d;
            margin-top: 4px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Live Audio Transcription</h1>
        
        <div id="connectionStatus" class="status-indicator disconnected">
            <span>‚óè</span>
            <span id="statusText">Not connected</span>
        </div>
        
        <div class="control-panel">
            <div class="form-group">
                <label for="audioSource" class="form-label">Input Source</label>
                <select id="audioSource" class="form-control">
                    <option value="default" selected>Default Microphone</option>
                </select>
            </div>
            
            <div class="form-group">
                <label class="form-label">Recording Mode</label>
                <div class="recording-mode-options">
                    <label class="mode-option">
                        <input type="radio" name="recordingMode" value="microphone" checked>
                        <span>Microphone</span>
                    </label>
                    <label class="mode-option">
                        <input type="radio" name="recordingMode" value="system">
                        <span>System Audio</span>
                    </label>
                    <label class="mode-option">
                        <input type="radio" name="recordingMode" value="both">
                        <span>Both</span>
                    </label>
                </div>
                <p class="form-hint">System audio works best in Chrome/Edge. Select "Share audio" when prompted.</p>
            </div>
            
            <div class="form-group">
                <label for="wsUrl" class="form-label">WebSocket URL</label>
                <input type="text" id="wsUrl" class="form-control" placeholder="ws://localhost:8080/ws" value="ws://localhost:8080/ws">
                <p class="form-hint">Backend WebSocket endpoint for live transcription</p>
            </div>
            
            <button id="startBtn" class="btn btn-primary" onclick="startLiveTranscription()">
                <svg width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M8 11a3 3 0 0 0 3-3V4a3 3 0 1 0-6 0v4a3 3 0 0 0 3 3z"/>
                    <path d="M14 10.5a.5.5 0 0 1-1 0A5 5 0 0 0 8 5.5a.5.5 0 0 1-1 0 6 6 0 0 1 12 0v.5z"/>
                </svg>
                Start Live Transcription
            </button>
            
            <button id="stopBtn" class="btn btn-danger" onclick="stopLiveTranscription()" disabled>
                <svg width="16" height="16" fill="currentColor" viewBox="0 0 16 16">
                    <path d="M5 3.5h6A1.5 1.5 0 0 1 12.5 5v6a1.5 1.5 0 0 1-1.5 1.5H5A1.5 1.5 0 0 1 3.5 11V5A1.5 1.5 0 0 1 5 3.5z"/>
                </svg>
                Stop Transcription
            </button>
        </div>
        
        <div id="recordingStatus" class="recording-status hidden">
            <span class="recording-dot"></span>
            Live transcription in progress...
            <div id="recordingTime" class="recording-time">00:00</div>
        </div>
        
        <div id="audioVisualizer" class="audio-visualizer hidden">
            <div id="visualizerBars" class="audio-visualizer-bars"></div>
        </div>
        
        <div class="main-content-area">
            <div class="transcription-container">
                <div style="display: flex; justify-content: space-between; align-items: center; margin-bottom: 15px;">
                    <h2>Live Transcription Output</h2>
                    <button id="clearBtn" class="btn btn-outline" onclick="clearTranscripts()" disabled>
                        Clear Transcripts
                    </button>
                </div>
                
                <div id="statsContainer" class="stats-container" style="display: none;">
                    <div class="stat-item">
                        <div class="stat-value" id="transcriptCount">0</div>
                        <div>Transcripts</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="wordsCount">0</div>
                        <div>Words</div>
                    </div>
                    <div class="stat-item">
                        <div class="stat-value" id="sessionTime">00:00</div>
                        <div>Session Time</div>
                    </div>
                </div>
                
                <div id="transcriptionOutput" class="transcription-output empty">
                    No transcription yet. Start recording to see live results...
                </div>
            </div>

            <div class="summary-container">
                <h2>Live Summary & Key Points</h2>
                <div class="form-group" style="margin-bottom: 15px;">
                    <label for="summaryPrompt" class="form-label">Summary Prompt</label>
                    <textarea id="summaryPrompt" class="form-control" rows="3">Summarize the key discussion points and action items from the ongoing conversation.</textarea>
                    <p class="form-hint">This prompt will guide the AI in generating the summary.</p>
                </div>
                <div id="summaryOutput" class="summary-output empty">
                    Summary will appear here as transcription progresses...
                </div>
            </div>
        </div>
    </div>

    <script src="live_audio_recorder.js"></script>
    <script>
        let audioRecorder = null;
        let transcriptionStats = {
            count: 0,
            words: 0,
            sessionStart: null
        };
        let sessionTimer = null;

        // Initialize audio devices on page load
        window.addEventListener('load', async function() {
            audioRecorder = new LiveAudioRecorder();
            try {
                await audioRecorder.populateAudioDevices();
                console.log('Audio devices populated');
            } catch (error) {
                console.error('Error initializing audio devices:', error);
            }
        });

        // Listen for transcription events
        document.addEventListener('transcription', function(event) {
            const data = event.detail;
            updateTranscriptionOutput(data);
        });

        // Listen for recorder errors
        document.addEventListener('recordererror', function(event) {
            const errorMessage = event.detail.message;
            updateConnectionStatus('disconnected', `Error: ${errorMessage}`);
            alert(`Recording Error: ${errorMessage}`);
            stopLiveTranscription(); // Attempt to stop recording on error
        });

        // Listen for recorder closed event
        document.addEventListener('recorderclosed', function(event) {
            console.log('Recorder closed event received:', event.detail);
            stopLiveTranscription(); // Ensure UI is reset when recorder closes
        });

        function updateConnectionStatus(status, message) {
            const statusElement = document.getElementById('connectionStatus');
            const statusText = document.getElementById('statusText');
            const startBtn = document.getElementById('startBtn');
            const stopBtn = document.getElementById('stopBtn');
            const clearBtn = document.getElementById('clearBtn');
            
            statusElement.className = `status-indicator ${status}`;
            statusText.textContent = message;

            if (status === 'connected') {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                clearBtn.disabled = false;
                document.getElementById('recordingStatus').classList.remove('hidden');
                document.getElementById('audioVisualizer').classList.remove('hidden');
                document.getElementById('statsContainer').style.display = 'flex';
            } else if (status === 'disconnected') {
                startBtn.disabled = false;
                stopBtn.disabled = true;
                document.getElementById('recordingStatus').classList.add('hidden');
                document.getElementById('audioVisualizer').classList.add('hidden');
                document.getElementById('statsContainer').style.display = 'none';
                // clearBtn.disabled = true; // Only disable if no transcripts are present
            } else if (status === 'connecting') {
                startBtn.disabled = true;
                stopBtn.disabled = true;
                clearBtn.disabled = true;
            }
        }

        function updateTranscriptionOutput(data) {
            const output = document.getElementById('transcriptionOutput');
            
            if (output.classList.contains('empty')) {
                output.classList.remove('empty');
                output.innerHTML = '';
            }

            // Create transcript entry based on data type
            const entry = document.createElement('div');
            entry.className = 'transcript-entry';
            
            let entryType = 'interim';
            let displayText = '';
            let timestamp = new Date().toLocaleTimeString();
            
            if (data.type === 'transcription') {
                entryType = data.final ? 'final' : 'interim';
                displayText = data.text || '';
                if (data.timestamp) {
                    timestamp = new Date(data.timestamp).toLocaleTimeString();
                }
            } else if (data.type === 'response') {
                entryType = 'response';
                displayText = data.text || '';
                entry.classList.add('response');
            } else {
                // Handle legacy format
                displayText = data.text || data.transcript || data;
                entryType = 'final';
            }

            if (entryType === 'final') {
                entry.classList.add('final');
            } else if (entryType === 'interim') {
                entry.classList.add('interim');
            }

            const metaDiv = document.createElement('div');
            metaDiv.className = 'transcript-meta';
            metaDiv.textContent = `${timestamp} ‚Ä¢ ${entryType === 'response' ? 'AI Response' : (entryType === 'final' ? 'Final' : 'Interim')}`;
            
            const textDiv = document.createElement('div');
            textDiv.className = 'transcript-text';
            textDiv.textContent = displayText;
            
            entry.appendChild(metaDiv);
            entry.appendChild(textDiv);

            // For interim results, replace the last interim entry if it exists
            if (entryType === 'interim') {
                const lastEntry = output.lastElementChild;
                if (lastEntry && lastEntry.classList.contains('interim')) {
                    output.removeChild(lastEntry);
                }
            }

            output.appendChild(entry);
            
            // Update stats for final transcriptions
            if (entryType === 'final' && displayText.trim()) {
                transcriptionStats.count++;
                transcriptionStats.words += displayText.trim().split(/\s+/).length;
                updateStats();
            }

            // Scroll to bottom
            output.scrollTop = output.scrollHeight;
        }

        function updateStats() {
            document.getElementById('transcriptCount').textContent = transcriptionStats.count;
            document.getElementById('wordsCount').textContent = transcriptionStats.words;
            
            if (transcriptionStats.sessionStart) {
                const elapsed = Math.floor((Date.now() - transcriptionStats.sessionStart) / 1000);
                const minutes = Math.floor(elapsed / 60).toString().padStart(2, '0');
                const seconds = (elapsed % 60).toString().padStart(2, '0');
                document.getElementById('sessionTime').textContent = `${minutes}:${seconds}`;
            }
        }

        function clearTranscripts() {
            const output = document.getElementById('transcriptionOutput');
            output.classList.add('empty');
            output.textContent = 'No transcription yet. Start recording to see live results...';
            
            // Reset stats
            transcriptionStats.count = 0;
            transcriptionStats.words = 0;
            updateStats();
            
            document.getElementById('statsContainer').style.display = 'none';
            document.getElementById('clearBtn').disabled = true;
        }

        async function startLiveTranscription() {
            if (!audioRecorder) {
                updateConnectionStatus('disconnected', 'Audio recorder not initialized');
                return;
            }

            const wsUrl = document.getElementById('wsUrl').value.trim();
            if (!wsUrl) {
                alert('Please enter a WebSocket URL');
                return;
            }

            try {
                updateConnectionStatus('connecting', 'Connecting...');
                
                const recordingMode = document.querySelector('input[name="recordingMode"]:checked').value;
                const summaryPrompt = document.getElementById('summaryPrompt').value.trim();
                await audioRecorder.startRecording(wsUrl, recordingMode, summaryPrompt);
                
                // Initialize session tracking
                transcriptionStats.sessionStart = Date.now();
                sessionTimer = setInterval(updateStats, 1000);
                
                // Clear previous transcription display
                const output = document.getElementById('transcriptionOutput');
                output.classList.add('empty');
                output.textContent = 'Listening for audio...';
                
            } catch (error) {
                console.error('Error starting live transcription:', error);
                updateConnectionStatus('disconnected', `Error: ${error.message}`);
                
                // Reset UI on error (handled by updateConnectionStatus and recordererror event)
                if (sessionTimer) {
                    clearInterval(sessionTimer);
                    sessionTimer = null;
                }
            }
        }

        function stopLiveTranscription() {
            if (!audioRecorder) {
                return;
            }

            audioRecorder.stopRecording();
            
            // Stop session timer
            if (sessionTimer) {
                clearInterval(sessionTimer);
                sessionTimer = null;
            }
            
            // Update UI
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('recordingStatus').classList.add('hidden');
            document.getElementById('audioVisualizer').classList.add('hidden');
            
            updateConnectionStatus('disconnected', 'Disconnected');
            
            // Add session end marker
            const output = document.getElementById('transcriptionOutput');
            if (!output.classList.contains('empty')) {
                const endEntry = document.createElement('div');
                endEntry.className = 'transcript-entry';
                endEntry.style.textAlign = 'center';
                endEntry.style.fontStyle = 'italic';
                endEntry.style.color = '#6c757d';
                endEntry.style.borderLeft = '4px solid #6c757d';
                endEntry.innerHTML = '<div class="transcript-text">--- Recording session ended ---</div>';
                output.appendChild(endEntry);
                output.scrollTop = output.scrollHeight;
            } else {
                output.classList.add('empty');
                output.textContent = 'No transcription received. Start recording to see live results...';
            }
        }

        // Make functions globally accessible
        window.startLiveTranscription = startLiveTranscription;
        window.stopLiveTranscription = stopLiveTranscription;

        // Handle page unload
        window.addEventListener('beforeunload', function() {
            if (audioRecorder && audioRecorder.getRecordingState().isRecording) {
                audioRecorder.stopRecording();
            }
        });
    </script>
</body>
</html>